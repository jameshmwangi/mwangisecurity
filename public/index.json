
[{"content":"","date":"23 October 2024","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","date":"23 October 2024","externalUrl":null,"permalink":"/categories/cisco-labs/","section":"Categories","summary":"","title":"Cisco Labs","type":"categories"},{"content":"","date":"23 October 2024","externalUrl":null,"permalink":"/tags/ctf/","section":"Tags","summary":"","title":"CTF","type":"tags"},{"content":"","date":"23 October 2024","externalUrl":null,"permalink":"/categories/cyber-forensics/","section":"Categories","summary":"","title":"Cyber Forensics","type":"categories"},{"content":"","date":"23 October 2024","externalUrl":null,"permalink":"/tags/enterprise-networking/","section":"Tags","summary":"","title":"Enterprise-Networking","type":"tags"},{"content":"","date":"23 October 2024","externalUrl":null,"permalink":"/tags/hackthebox/","section":"Tags","summary":"","title":"Hackthebox","type":"tags"},{"content":"","date":"23 October 2024","externalUrl":null,"permalink":"/categories/hackthebox/","section":"Categories","summary":"","title":"HackTheBox","type":"categories"},{"content":"","date":"23 October 2024","externalUrl":null,"permalink":"/tags/ids/","section":"Tags","summary":"","title":"IDS","type":"tags"},{"content":"","date":"23 October 2024","externalUrl":null,"permalink":"/tags/intrusion-detection/","section":"Tags","summary":"","title":"Intrusion-Detection","type":"tags"},{"content":"","date":"23 October 2024","externalUrl":null,"permalink":"/","section":"J.Mwangi Cybersecurity","summary":"","title":"J.Mwangi Cybersecurity","type":"page"},{"content":"","date":"23 October 2024","externalUrl":null,"permalink":"/categories/network-configuration/","section":"Categories","summary":"","title":"Network Configuration","type":"categories"},{"content":"","date":"23 October 2024","externalUrl":null,"permalink":"/categories/network-security/","section":"Categories","summary":"","title":"Network Security","type":"categories"},{"content":"","date":"23 October 2024","externalUrl":null,"permalink":"/categories/network-traffic-analysis/","section":"Categories","summary":"","title":"Network Traffic Analysis","type":"categories"},{"content":"\rIntroduction #\rNetwork Traffic Analysis (NTA) involves analyzing network traffic to identify prevalent ports and protocols, establish a baseline for the network environment, monitor and address potential threats, and gain comprehensive insights into the organization\u0026rsquo;s network infrastructure. By enabling security experts to promptly and accurately detect anomalies, such as security threats, NTA plays a crucial role in enhancing network security. Furthermore, NTA supports adherence to security protocols by identifying evolving attack strategies aimed at bypassing detection and leveraging authorized tools within network systems, posing challenges for cybersecurity defenders.\nObjectives: #\r- Enhance understanding of TCP/IP stack \u0026amp; OSI model\n-Analysis using Tcpdump \u0026amp; Wireshark\nKnowledge Check * ?\nNetworking Primer – Layers 1-4 #\rHow many layers does the OSI model have?\n7\nHow many layers are there in the TCP/IP model?\n4\nTrue or False: Routers operate at layer 2 of the OSI model?\nFalse\nWhat addressing mechanism is used at the Link Layer of the TCP/IP model?\nMac-Address\nAt what layer of the OSI model is a PDU encapsulated into a packet? ( the number )\n3\nWhat addressing mechanism utilizes a 32-bit address?\nIPv4\nWhat Transport layer protocol is connection-oriented?\nTCP\nWhat Transport Layer protocol is considered unreliable?\nUDP\nTCP’s three-way handshake consists of 3 packets: 1.Syn, 2.Syn \u0026amp; ACK, 3. _? What is the final packet of the handshake?\nACK\nNetworking Primer — Layers 5–7\nWhat is the default operational mode method used by FTP?\nactive\nFTP utilizes what two ports for command and data transfer? (separate the two numbers with a space)\n20 21\nDoes SMB utilize TCP or UDP as its transport layer protocol?\nTCP\nSMB has moved to using what TCP port?\n445\nHypertext Transfer Protocol uses what well-known TCP port number?\n80\nWhat HTTP method is used to request information and content from the web server?\nGET\nTrue or False: When utilizing HTTPS, all data sent across the session will appear as TLS Application data?\nTrue\nTCPdump Fundamentals #\r(Question-1.zip had an image , attached below)\nUtilizing the output shown in question-1.png, who is the server in this communication? (IP Address)\n174.143.213.184\nWere absolute or relative sequence numbers used during the capture? (see question-1.zip to answer)\nRelative\nIf I wish to start a capture without hostname resolution, verbose output, showing contents in ASCII and hex, and grab the first 100 packets; what are the switches used? please answer in the order the switches are asked for in the question.\n-nvXc 100\nGiven the capture file at /tmp/capture.pcap, what tcpdump command will enable you to read from the capture and show the output contents in Hex and ASCII? (Please use best practices when using switches)\nsudo tcpdump -Xr /tmp/capture.pcap\nWhat TCPDump switch will increase the verbosity of our output? ( Include the — with the proper switch )\n-v\nWhat built-in terminal help reference can tell us more about TCPDump?\nMan\nWhat TCPDump switch will let me write my output to a file?\n-w\nFundamentals Lab\nWhat TCPDump switch will allow us to pipe the contents of a pcap file out to another function such as ‘grep’?\n-l\nTrue or False: The filter “port” looks at source and destination traffic.\nTrue\nIf we wished to filter out ICMP traffic from our capture, what filter could we use? ( word only, not symbol please.)\nnot icmp\nWhat command will show you where / if TCPDump is installed?\nwhich tcpdump\nHow do you start a capture with TCPDump to capture on eth0?\ntcpdump -i eth0\nWhat switch will provide more verbosity in your output?\n-v\nWhat switch will write your capture output to a .pcap file?\n-w\nWhat switch will read a capture from a .pcap file?\n-r\nWhat switch will show the contents of a capture in Hex and ASCII?\n-X\nTcpdump Packet Filtering #\rWhat filter will allow me to see traffic coming from or destined to the host with an ip of 10.10.20.1?\nhost 10.10.20.1\nWhat filter will allow me to capture based on either of two options?\nor\nTrue or False: TCPDump will resolve IPs to hostnames by default\nTrue\nInterrogating Network Traffic With Capture and Display Filters #\r(The section requires we unzip TCPDump-lab-2.zip)\nWhat are the client and server port numbers used in first full TCP three-way handshake? (low number first then high number)\n80 43806\nBased on the traffic seen in the pcap file, who is the DNS server in this network segment? (ip address)\n172.16.146.1\nAnalysis with Wireshark\nTrue or False: Wireshark can run on both Windows and Linux.\nTrue\nWhich Pane allows a user to see a summary of each packet grabbed during the capture?\nPacket List\nWhich pane provides you insight into the traffic you captured and displays it in both ASCII and Hex?\nPacket Bytes\nWhat switch is used with TShark to list possible interfaces to capture on?\n-D\nWhat switch allows us to apply filters in TShark?\n-f\nIs a capture filter applied before the capture starts or after? (answer before or after)\nBefore\nWireshark Advanced Usage #\rWhich plugin tab can provide us with a way to view conversation metadata and even protocol breakdowns for the entire PCAP file?\nStatistics\nWhat plugin tab will allow me to accomplish tasks such as applying filters, following streams, and viewing expert info?\nAnalyze\nWhat stream-oriented Transport protocol enables us to follow and rebuild conversations and the included data?\nTCP\nTrue or False: Wireshark can extract files from HTTP traffic.\nTrue\nTrue or False: The ftp-data filter will show us any data sent over TCP port 21.\nFalse\nPacket Inception, Dissecting Network Traffic With Wireshark #\rWhat was the filename of the image that contained a certain Transformer Leader? (name.filetype)\nRise-Up.jpg\nWhich employee is suspected of performing potentially malicious actions in the live environment?\nBob\nGuided Lab: Traffic Analysis Workflow #\rWhat was the name of the new user created on Mr. Ben’s host?\nhacker\nHow many total packets were there in the Guided-analysis PCAP?\n44\nWhat was the suspicious port that was being used?\n4444\nDecrypting RDP connections #\rWhat user account was used to initiate the RDP connection?\nBucky\nGlad to share this achievement: https://academy.hackthebox.com/achievement/1317759/81\nConclusion #\rCompleting the Network Traffic Analysis module has given me a solid foundation in analyzing and interpreting network data, which is essential in cybersecurity. By working hands-on with tools like Wireshark and tcpdump, I’ve learned to spot malicious patterns and leverage intrusion detection systems effectively. This experience has strengthened my skills in detecting network anomalies and has equipped me with practical tools and methodologies that I can apply in real-world network defense and threat intelligence scenarios.\n","date":"23 October 2024","externalUrl":null,"permalink":"/posts/network-traffic-analysis/","section":"Posts","summary":"Networking article series","title":"Network Traffic Analysis","type":"posts"},{"content":"","date":"23 October 2024","externalUrl":null,"permalink":"/tags/network-configuration/","section":"Tags","summary":"","title":"Network-Configuration","type":"tags"},{"content":"","date":"23 October 2024","externalUrl":null,"permalink":"/tags/packet-inspection/","section":"Tags","summary":"","title":"Packet-Inspection","type":"tags"},{"content":"","date":"23 October 2024","externalUrl":null,"permalink":"/tags/packet-tracer/","section":"Tags","summary":"","title":"Packet-Tracer","type":"tags"},{"content":"","date":"23 October 2024","externalUrl":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":"","date":"23 October 2024","externalUrl":null,"permalink":"/tags/radius/","section":"Tags","summary":"","title":"RADIUS","type":"tags"},{"content":"","date":"23 October 2024","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"23 October 2024","externalUrl":null,"permalink":"/tags/tcpdump/","section":"Tags","summary":"","title":"Tcpdump","type":"tags"},{"content":"","date":"23 October 2024","externalUrl":null,"permalink":"/tags/traffic-analysis/","section":"Tags","summary":"","title":"Traffic-Analysis","type":"tags"},{"content":"","date":"23 October 2024","externalUrl":null,"permalink":"/categories/wireless-networks/","section":"Categories","summary":"","title":"Wireless Networks","type":"categories"},{"content":"","date":"23 October 2024","externalUrl":null,"permalink":"/tags/wireless-security/","section":"Tags","summary":"","title":"Wireless-Security","type":"tags"},{"content":"","date":"23 October 2024","externalUrl":null,"permalink":"/tags/wireshark/","section":"Tags","summary":"","title":"Wireshark","type":"tags"},{"content":"\rIntroduction #\rA Wireless Local Area Network (WLAN) leverages radio frequency transmissions to establish network connectivity amongst co-located devices within a defined geographical area. This eliminates the need for physical cabling, facilitating user mobility while maintaining network access.\nObjectives: #\rIn this activity, I will configure both a wireless home router and a Wireless local controller (WLC)-based network. I will implement both WPA2-PSK and WPA2-Enterprise security. Configure a home router to provide Wi-Fi connectivity to a variety of devices. Configure WPA2-PSK security on a home router. Configure interfaces on a WLC. Configure WLANs on a WLC. Configure WPA2-PSK security on a WLAN and connect hosts to a WLAN. Configure WPA2-Enteprise on a WLAN and connect hosts to the WLAN. Verify connectivity \u0026amp; WLAN connectivity\nPart 1: Configure a Home Wireless Router #\rTo change the DHCP settings I access the Home Wireless Router GUI and change the router IP and DHCP settings according to the information in the Addressing Table. I set the maximum number of users to 20. Start IP address from 3. The static DNS server with the address 10.100.100.252. The internet IP address 10.100.200.2 /27. The subnet /27 is 255.255.255.0\nTo configure WLAN, I used the 2.4GHz WLAN interface in the Basic Wireless Settings tab. The SSID name is Home SSID. I choose the standard channel 6 – 2.437 GHz. I enabled the SSID broadcast\nTo configure security in the wireless security tab I choose the WPA2 Personal option and the passphrase as Cisco123.\nI also changed the default password to Cisco123. Default passwords are common and easy to be compromised thus the need to change it.\nNext, I connect clients to the network. I opened the PC Wireless app on the desktop of the laptop. I picked the SSID named Home SSID which I configured earlier with the password Cisco123.\nThe laptop once connected had some parallel lines connecting it to the router representing the wireless connection was active\nFor the smartphone I configured it under the config wireless panel to the same SSID and credentials as the tablet and the laptop.\nThe tablet configuration is shown above.\nTo verify the connection was active I performed ping from the laptop to 192.168.6.5- Smartphone, 192.168.6.5-tablet, to the webserver IP address 203.0.113.78 and www.netacad.pt . The ping were successful.\nPart 2: Configure a WLC Controller Network #\rIn this part one WLAN will use WPA2-PSK authentication. The other WLAN will use WPA2-Enterprise authentication. I will also configure the WLC to use an SNMP server and configure a DHCP scope that will be used by the wireless management network.\nTo configure VLAN interfaces I accessed the Enterprise Admin and navigated to WLC-1 management interface via a web browser. To log into WLC-1,I used admin as the username and Cisco123 as the password.\nThe first WLAN was WLAN 2 controller The setting for WLAN 2 can be seen below\nTo configure WLAN 5, I followed similar steps as WLAN 2\nThe next step is to configure a DHCP scope for the wireless management network with the specification offered in the lab.\nIn step 3, I configured the WLC with external server addresses. Under the Security tab I configured a new RADIUS authentication server with index 1.\nI also configured a WLC to send logs information to an SNMP server. Community Name: WLAN\nIP address: 10.6.0.254\nIn step 4, I created the WLAN’s and enabled them\nThe WPA2-PSK security was used by Wireless VLAN 2. Also had to enable Enable FlexConnect Local Switching and FlexConnect Local Auth.\nThe second profile Wireless VLAN 5 used 802.1x - WPA2-Enterprise security . I configured it accordingly.\nIn step 5 , Wireless Host 1 should connect to Wireless VLAN 2.Wireless Host 2 should connect to Wireless VLAN 5 using the credentials in the WLAN information table.\nFrom Wireless Host 1 I selected SSID 2 and typed the password as Cisco123. The connection went through.\nSince Wireless VLAN 5 used 802.1x - WPA2-Enterprise security, the connection had to happen via a profile creation using the details provided in the addressing table.\nBoth Wireless hosts were now connected to the network.\nTo test the network I ping the IP and URL to the webserver www.netacad.pt .\nWireless host 1:\nWireless host 2:\nConclusion #\rThrough this comprehensive laboratory experience with Packet Tracer, I gained practical expertise in implementing both residential and enterprise wireless security solutions. The progression from configuring a basic wireless home router to implementing a WLC-based network provided invaluable hands-on experience with both WPA2-PSK and WPA2-Enterprise security protocols. By methodically working through each configuration step - from setting up wireless interfaces and establishing WLANs on the WLC to implementing varying levels of security protocols - I developed a thorough understanding of secure wireless deployment practices. The practical verification of connectivity across different security configurations demonstrated the real-world implications of each implementation choice, reinforcing the importance of proper security protocol selection and configuration in wireless networking.\n_\n","date":"23 October 2024","externalUrl":null,"permalink":"/posts/wlan-configuration/","section":"Posts","summary":"Networking configuration article series","title":"WLAN Configuration","type":"posts"},{"content":"","date":"23 October 2024","externalUrl":null,"permalink":"/tags/wlan-security/","section":"Tags","summary":"","title":"Wlan-Security","type":"tags"},{"content":"","date":"16 September 2024","externalUrl":null,"permalink":"/tags/aws-security/","section":"Tags","summary":"","title":"Aws Security","type":"tags"},{"content":"","date":"16 September 2024","externalUrl":null,"permalink":"/categories/aws-security/","section":"Categories","summary":"","title":"Aws Security","type":"categories"},{"content":"","date":"16 September 2024","externalUrl":null,"permalink":"/categories/cloud-security/","section":"Categories","summary":"","title":"Cloud Security","type":"categories"},{"content":"","date":"16 September 2024","externalUrl":null,"permalink":"/tags/cloud-vulnerabilities/","section":"Tags","summary":"","title":"Cloud Vulnerabilities","type":"tags"},{"content":"","date":"16 September 2024","externalUrl":null,"permalink":"/tags/encryption/","section":"Tags","summary":"","title":"Encryption","type":"tags"},{"content":"","date":"16 September 2024","externalUrl":null,"permalink":"/tags/flaws.cloud/","section":"Tags","summary":"","title":"Flaws.cloud","type":"tags"},{"content":"","date":"16 September 2024","externalUrl":null,"permalink":"/categories/flaws.cloud/","section":"Categories","summary":"","title":"Flaws.cloud","type":"categories"},{"content":"\rIntroduction #\rIn the Flaws AWS series of levels, we will learn about common mistakes and pitfalls when using Amazon Web Services (AWS). By participating in this challenge, we will gain hands-on experience with AWS-specific issues and learn how to avoid them in our own projects. As we progress through the levels, we will confront various security vulnerabilities that commonly occur in AWS environments, where our task is to identify and exploit these vulnerabilities, gaining insights into how they can be mitigated. The goal is to provide us with a deeper understanding of AWS security best practices. Each level presents a scenario with a specific AWS security flaw, and we will learn how to discover and exploit these vulnerabilities in a controlled environment. A series of hints will guide us through each level, teaching us the commands and techniques needed to uncover the information required to solve the challenges.\nObjective: #\rS3 Bucket Permissions: Understand and correct overly permissive S3 bucket policies. Identify an S3 bucket that is publicly accessible and contains sensitive information. Learn how to use AWS Identity and Access Management (IAM) policies to restrict access to S3 buckets. AWS CLI Access : Use the AWS Command Line Interface (CLI) to retrieve and find sensitive data. Understand the importance of being aware of the scope of permissions granted, especially when using broad permissions like Any Authenticated AWS User preventing unauthorized data retrieval.\nIAM access keys: Identify an IAM role with excessive permissions and exploit it to access other AWS s3 bucket resources. See the importance of always revoking any AWS keys or any secrets that could have been leaked or were misplaced.\nProtect Backups and Snapshots:Implement stringent access controls to secure backups and snapshots of EC2 instances and databases, as they can be exploited by attackers to gain unauthorized access.\nSecure Metadata Service Access: Ensure the metadata service endpoint (169.254.169.254) is properly secured to prevent the exposure of sensitive information\nMonitor Read-Only Permissions :Identify why it’s proactive to be cautious with read-only permissions, such as the SecurityAudit policy, as they can inadvertently aid attackers in identifying vulnerabilities. Regularly review and manage these permissions to maintain a secure environment.\nLevel 1 : #\rThe site flaws.cloud is hosted as an S3 bucket. This is a great way to host a static site, similar to hosting one via github pages. to confirm the hosting . You can determine the site is hosted as an S3 bucket by running a DNS lookup on the domain, such as:\n$dig +nocmd flaws.cloud any +multiline +noall +answer\nTo know the region of the s3 bucket we do an nslookup on flaws.cloud and sub sequent nslookup on one of the returned IP address as shown below\nfrom the displayed information the s3 bucket is located in the “us-west-2” region. If we browse the bucket via aws s3 ls s3://flaws.cloud/ \u0026ndash;no-sign-request \u0026ndash;region us-west-2\nwe can see there is a secret html page\nFinally, we can also just visit http://flaws.cloud.s3.amazonaws.com/ which lists the files due to the permissions issues on this bucket.\nfrom here we can get the secret and access it from : http://flaws.cloud.s3.amazonaws.com/secret-dd02c7c.html\nThe page takes us to level 2. Lesson learned level 1\nOn AWS you can set up S3 buckets with all sorts of permissions and functionality including using them to host static files. A number of people accidentally open them up with permissions that are too loose. Just like how you shouldn\u0026rsquo;t allow directory listings of web servers, you shouldn\u0026rsquo;t allow bucket listings.\nif proprietary data is uploaded to the bucket then it would be exposed to attackers and everyone on the internet. Level 2: #\rSimilar to the first level, you can discover that this sub-domain is hosted as an S3 bucket with the name \u0026ldquo;level2-c8b217a33fcf1f839f6f1f73a00a9ae7.flaws.cloud\u0026rdquo;. Its permissions are too loose, but you need your own AWS account to see what\u0026rsquo;s inside. Using my account I run:\naws s3 \u0026ndash;profile hourglass ls s3://level2-c8b217a33fcf1f839f6f1f73a00a9ae7.flaws.cloud\nfrom the terminal results we can access the flag page via\nhttp://level2-c8b217a33fcf1f839f6f1f73a00a9ae7.flaws.cloud/secret-e4443fc.html\nalternatively we can download all the files via sync and open the secret html page in a browser : file:///home/cyberchaosjedi/Music/Friday/secret-e4443fc.html\nLesson learned level2\nSimilar to opening permissions to \u0026ldquo;Everyone\u0026rdquo;, people accidentally open permissions to \u0026ldquo;Any Authenticated AWS User\u0026rdquo;. They might mistakenly think this will only be users of their account, when in fact it means anyone that has an AWS account.\nLevel 3: #\rWe download the level 3 files via sync :\naws s3 sync s3://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud/ . \u0026ndash;no-sign-request \u0026ndash;region us-west-2\nto view all files including the hidden ones we can use : ls -la\nfrom the list we have a .git file. People often accidentally add secret things to git repos, and then try to remove them without revoking or rolling the secrets. You can look through the history of a git repo by running:\ngit log\nThere are 2 versions of the commit. Then you can look at what a git repo looked like at the time of a commit by running:\ngit checkout f7cebc46b471ca9838a0bdd1074bb498a3f84c87\nwhere `f7cebc46b471ca9838a0bdd1074bb498a3f84c87` would be the hash for the commit shown in `git log`.\ngit checkout f52ec03b227ea6094b04e43f475fb0126edb5a61 if we list we can find a sensitive key file that was left\ncat access_key.txt\nwe can configure a profile flawsaws with the credentials , following is the “who am I “ identity check using aws sts get-caller-identity – profile flawaws\nThen to list S3 buckets using that profile run:\naws \u0026ndash;profile flawsaws s3 ls\nWe have listed all the buckets available in the profile. the next level 4 : http://level4-1156739cfb264ced6de514971a4bef68.flaws.cloud/\nLesson learned level 3\nPeople often leak AWS keys and then try to cover up their mistakes without revoking the keys. You should always revoke any AWS keys (or any secrets) that could have been leaked or were misplaced. Roll your secrets early and often.\nAnother interesting issue this level has exhibited, although not that worrisome, is that you can\u0026rsquo;t restrict the ability to list only certain buckets in AWS, so if you want to give an employee the ability to list some buckets in an account, they will be able to list them all. The key you used to discover this bucket can see all the buckets in the account. You can\u0026rsquo;t see what is in the buckets, but you\u0026rsquo;ll know they exist. Similarly, be aware that buckets use a global namespace meaning that bucket names must be unique across all customers, so if you create a bucket named `merger_with_company_Y` or something that is supposed to be secret, it\u0026rsquo;s technically possible for someone to discover that bucket exists.\nLevel 4: #\rYou can snapshot the disk volume of an EC2 as a backup. In this case, the snapshot was made public, but you\u0026rsquo;ll need to find it.\nTo do this, first we need the account ID, which we can get using the AWS key from the previous level:\naws \u0026ndash;profile flaws sts get-caller-identity\nthe account is 975426262029\nThe ARN shows the account is /backup . The backups this account makes are snapshots of EC2s. Next, discover the snapshot: aws \u0026ndash;profile flawsaws ec2 describe-snapshots \u0026ndash;owner-id 975426262029\nBy default snapshots are private, and you can transfer them between accounts securely by specifying the account ID of the other account, but a number of people just make them public and forget about them it seems.\nNow that you know the snapshot ID, you\u0026rsquo;re going to want to mount it. You\u0026rsquo;ll need to do this in your own AWS account.\nFirst, create a volume using the snapshot:\naws \u0026ndash;profile hourglass ec2 create-volume \u0026ndash;availability-zone us-west-2a \u0026ndash;region us-west-2 \u0026ndash;snapshot-id snap-0b49342abd1bdcb89\nchoose the volume you just created. create a new ec2 instance , an rsa pair key and SSH into the instance\nto get the ssh link , click the instance and select Connect\nGrant read access chmod 400\nthen ssh -i \u0026ldquo;flaws-access-key.pem\u0026rdquo; ec2-user@ec2-54-190-59-246.us-west-2.compute.amazonaws.com\nWe\u0026rsquo;ll need to mount this extra volume by running:\nlsblk\nsudo file -s /dev/xvdb1\n# Next we mount it sudo mount /dev/xvdb1 /mnt followed by verification\nwe navigate to /mnt , home folder , ubuntu and check the content of the nginx configuration file\nhere we get credentials to log into : http://4d0cf09b9b2d761a7d87be99d17507bce8b86f3b.flaws.cloud/\nLesson learned level 4\nAWS allows you to make snapshots of EC2\u0026rsquo;s and databases (RDS). The main purpose for that is to make backups, but people sometimes use snapshots to get access back to their own EC2\u0026rsquo;s when they forget the passwords. This also allows attackers to get access to things. Snapshots are normally restricted to your own account, so a possible attack would be an attacker getting access to an AWS key that allows them to start/stop and do other things with EC2\u0026rsquo;s and then uses that to snapshot an EC2 and spin up an EC2 with that volume in your environment to get access to it. Like all backups, you need to be cautious about protecting them.\nLevel 5: #\rThis EC2 has a simple HTTP only proxy on it. Here are some examples of it\u0026rsquo;s usage:\nhttp://4d0cf09b9b2d761a7d87be99d17507bce8b86f3b.flaws.cloud/proxy/flaws.cloud/\nhttp://4d0cf09b9b2d761a7d87be99d17507bce8b86f3b.flaws.cloud/proxy/summitroute.com/blog/feed.xml\nhttp://4d0cf09b9b2d761a7d87be99d17507bce8b86f3b.flaws.cloud/proxy/neverssl.com/\nHTTP may be vulnerable to SSRF (Server-Side Request Forgery) . We can try accessing the metadata\nvia http://4d0cf09b9b2d761a7d87be99d17507bce8b86f3b.flaws.cloud/proxy/169.254.169.254/latest/meta-data\n169.254.169.254/latest/meta-data is a well known way of accessing the meta data of a service.\nThen :\nhttp://4d0cf09b9b2d761a7d87be99d17507bce8b86f3b.flaws.cloud/proxy/169.254.169.254/latest/meta-data/iam\nhttp://4d0cf09b9b2d761a7d87be99d17507bce8b86f3b.flaws.cloud/proxy/169.254.169.254/latest/meta-data/iam/security-credentials/\nhttp://4d0cf09b9b2d761a7d87be99d17507bce8b86f3b.flaws.cloud/proxy/169.254.169.254/latest/meta-data/iam/security-credentials/flaws\nWe have obtained access keys credentials used to run the IAM access , we can create a profile with cli access\nthen nano ~/.aws/credentials and add the session token found with the IAM role credentials.\nWe are to figure out how to list the contents of the level6 bucket at level6-cc4c404a8a8b876167f5e70a7d8c9880.flaws.cloud that has a hidden directory in it.\nUsing the created profile we list the contents\nthe directory is ddcc78ff and with a index.html\nhttp://level6-cc4c404a8a8b876167f5e70a7d8c9880.flaws.cloud/ddcc78ff/index.html\nLesson learned level 5\nThe IP address 169.254.169.254 is a magic IP in the cloud world. AWS, Azure, Google, DigitalOcean and others use this to allow cloud resources to find out metadata about themselves. Some, such as Google, have additional constraints on the requests, such as requiring it to use `Metadata-Flavor: Google` as an HTTP header and refusing requests with an `X-Forwarded-For` header. AWS has recently created a new IMDSv2 that requires special headers, a challenge and response, and other protections, but many AWS accounts may not have enforced it. If you can make any sort of HTTP request from an EC2 to that IP, you\u0026rsquo;ll likely get back information the owner would prefer you not see.\nA similar problem to getting access to the IAM profile\u0026rsquo;s access keys is access to the EC2\u0026rsquo;s user-data, which people sometimes use to pass secrets to the EC2 such as API keys or credentials.\nLevel 6: #\rWe set up a profile named flaws6 . using the provided IAM access key and secret key\nThe SecurityAudit group can get a high-level overview of the resources in an AWS account, but it\u0026rsquo;s also useful for looking at IAM policies. First, find out who you are (assuming you named your profile \u0026ldquo;level6\u0026rdquo;): aws \u0026ndash;profile flaws6 iam get-user\nWe find out the user is named level6\nTo find out what policies are attached to it:\naws \u0026ndash;profile flaws6 iam list-attached-user-policies \u0026ndash;user-name Level6\nthere are two policies attached\n\u0026ldquo;SecurityAudit\u0026rdquo;: This is an AWS managed policy that provides permissions necessary for security assessments. It is designed to allow users or roles to view (but not modify) a wide range of security-relevant resources and settings in an AWS account. \u0026ldquo;list_apigateways\u0026rdquo; a custom made policy. Once you know the ARN for the policy you can get it\u0026rsquo;s version id:\naws \u0026ndash;profile flaws6 iam get-policy \u0026ndash;policy-arn arn:aws:iam::975426262029:policy/list_apigateways\nThe policy id : \u0026ldquo;PolicyId\u0026rdquo;: \u0026ldquo;ANPAIRLWTQMGKCSPGTAIO\u0026rdquo;,\nNow that we have the ARN and the version id, we can see what the actual policy is:\naws \u0026ndash;profile flaws6 iam get-policy-version \u0026ndash;policy-arn arn:aws:iam::975426262029:policy/list_apigateways \u0026ndash;version-id v4\nThis tells us using this policy we can call \u0026ldquo;apigateway:GET\u0026rdquo; on \u0026ldquo;arn:aws:apigateway:us-west-2::/restapis/*\u0026rdquo;\nThe API gateway in this case is used to call a lambda function, but we need to figure out how to invoke it.\nThe SecurityAudit policy lets us see some things about lambdas:\naws \u0026ndash;region us-west-2 \u0026ndash;profile flaws6 lambda list-functions\nThat tells you there is a function named \u0026ldquo;Level6\u0026rdquo;, and the SecurityAudit also lets you run:\naws \u0026ndash;region us-west-2 \u0026ndash;profile flaws6 lambda get-policy \u0026ndash;function-name Level6\nThis tells us about the ability to execute `arn:aws:execute-api:us-west-2:975426262029:s33ppypa75/*/GET/level6\\` That \u0026ldquo;s33ppypa75\u0026rdquo; is a rest-api-id, which we can then use with the other attached policy:\naws \u0026ndash;profile flaws6 \u0026ndash;region us-west-2 apigateway get-stages \u0026ndash;rest-api-id \u0026ldquo;s33ppypa75\u0026rdquo;\nThat tells us the stage name is \u0026ldquo;Prod\u0026rdquo;. Lambda functions are called using the rest-api-id, stage name, region, and resource as https://s33ppypa75.execute-api.us-west-2.amazonaws.com/Prod/level6\n\u0026ldquo;Go to http://theend-797237e8ada164bf9f12cebf93b282cf.flaws.cloud/d730aa2b/\u0026rdquo;\nthe link navigates to the page :\nLesson learned level 6\nIt is common to give people and entities read-only permissions such as the SecurityAudit policy. The ability to read your own and other\u0026rsquo;s IAM policies can really help an attacker figure out what exists in your environment and look for weaknesses and mistakes.\nConclusion #\rThe flAWS.cloud challenge expounds the importance of rigorous security management in AWS environments. There is the necessity of carefully configuring permissions to avoid accidental data exposure, such as ensuring S3 buckets are not overly permissive. Understanding permission scopes is vital to prevent unauthorized access, especially when granting broad permissions that might be misconstrued, such as \u0026ldquo;Any Authenticated AWS User.\u0026rdquo; Promptly revoking and rotating compromised AWS keys is crucial to maintaining security. Additionally, safeguarding backups and snapshots is essential, as these can be exploited by attackers to gain unauthorized access. Properly securing the metadata service endpoint (169.254.169.254) is also critical, as it can expose sensitive information if not protected by measures like IMDSv2. Finally, even read-only permissions like the SecurityAudit policy can help attackers identify vulnerabilities if not managed carefully. Overall, the challenge highlights the need for diligent permission management, proactive credential handling, and vigilant protection of sensitive data to ensure a secure AWS environment.\n","date":"16 September 2024","externalUrl":null,"permalink":"/posts/flawsaws/","section":"Posts","summary":"Cloud security strategy article series","title":"Flaws.cloud Common AWS Vulnerabilities","type":"posts"},{"content":"","date":"16 September 2024","externalUrl":null,"permalink":"/tags/key-management/","section":"Tags","summary":"","title":"Key Management","type":"tags"},{"content":"","date":"16 September 2024","externalUrl":null,"permalink":"/tags/security-best-practices/","section":"Tags","summary":"","title":"Security Best Practices","type":"tags"},{"content":"","date":"16 September 2024","externalUrl":null,"permalink":"/categories/vulnerabilities/","section":"Categories","summary":"","title":"Vulnerabilities","type":"categories"},{"content":"","date":"20 August 2024","externalUrl":null,"permalink":"/tags/aws/","section":"Tags","summary":"","title":"Aws","type":"tags"},{"content":"","date":"20 August 2024","externalUrl":null,"permalink":"/categories/aws/","section":"Categories","summary":"","title":"Aws","type":"categories"},{"content":"\rIntroduction #\rThe AWS Key Management Service (KMS) provides secure storage and rotation of encryption keys with robust access control. For a cloud security engineer, it\u0026rsquo;s crucial to have a comprehensive understanding of AWS KMS to ensure the security and integrity of data. Mastery of AWS KMS involves learning how to create, manage, and use cryptographic keys effectively within AWS services and applications. This entails understanding key policies, utilizing both customer-managed and AWS-managed keys, enabling automatic key rotation, and integrating KMS with other AWS services to ensure consistent enforcement of data encryption and access controls.\nObjective: #\rDemonstrate the integration of AWS Key Management Service (KMS) with AWS services, such as Amazon S3 and Amazon EBS, to streamline the encryption and decryption process. This involves enabling data encryption within these services without requiring manual key management, showcasing how KMS simplifies secure data handling in cloud environments.\nLab implementation #\rLogin to your AWS Web console (root account) and create an IAM account.\n#\rI created an IAM user “kenya-one” and assigned the user admin privileges. Creating an IAM (Identity and Access Management) user account is recommended rather than using the root user account. An IAM user account provides a more secure way to access and manage AWS resources and services. By creating an IAM user account, you can specify the user’s permissions and restrict their access to only the necessary AWS resources and services. All the activities will be done in the IAM account.\nClick on Services. In the Search field, type KMS and then select Key Management Service. On the KMS Console page, click on Create Key.\nThere are two types of encryption, asymmetric and symmetric\nSymmetric encryption, involves using a single key for both encryption and decryption of data. This key must be securely shared between the communicating parties. Symmetric encryption is faster and more computationally efficient compared to asymmetric encryption, making it suitable for bulk data encryption. Used for encrypting data at rest (eg, EBS volumes, S3 objects) and protecting data in transit (eg, between AWS services).\nAsymmetric encryption, on the other hand, uses a pair of keys: a public key and a private key. The public key is used for encryption, while the private key is used for decryption. It enables secure communication and authentication without the need to share private keys, thus enhancing security in distributed systems and applications. Used for Secure key exchange (eg, encrypting symmetric keys for secure transmission), digital signatures for data integrity and authentication, and SSL/TLS encryption for secure web traffic.\nThere are five steps to the creation of the KMS: In the Configure key (Step 1), retain the default settings. Click on Next to continue.\nUnder Add Label (Step 2): Enter an alias of your choice as the name of your master key.\nThe description is optional. Click Next.\nDefine key administrative permissions (Step 3)\nTo allow users to perform encryption and decryption, I have to assign key permissions to them on the Define key administrative permissions page. Permit the user created in the previous lab to use the kenya-one-key by selecting the checkbox near the user. Here, we have selected the user kenya-one we created in the previous lab. Click on Next to continue.\nDefine key usage permissions (Step 4) . Here, you are trying to give the user key permission. You have the option to add another AWS user account. Select the user kenya-one and click on Next to continue.\nReview (Step 5) Review all settings and the key policy, which is in JSON format, and then click FINISH to create the master key. Now we have successfully created an AWS KMS for the IAM user kenya-one\nIntegrating the Created KMS to AWS services such as Amazon S3 and Amazon EBS\nLet\u0026rsquo;s start with Amazon S3 . In your AWS Management Console, type S3 in the search field to create a new bucket. On your S3 bucket page. Click an S3 Create bucket. The Create bucket popup appears. Under General Configuration, type the name of the bucket in the Bucket Name field -here, the bucket name is kenya-one-bucket.\nRetain the default Object Ownership setting and block this bucket\u0026rsquo;s public access settings. #\rEnable bucket versioning and retain the default tags and default encryption settings. Then, click on Create Bucket. The ‘kenya-one-bucket’ is created successfully.\nClick on the newly created bucket to configure the encryption settings Click on the bucket name ‘kenya-one-bucket’ to navigate the properties of the bucket. In the properties tab, ensure bucket versioning is enabled. Next, under default encryption, we select Server-side encryption with AWS Key Management Service keys (SSE-KMS).\nRetain the default setting (Enable) for Bucket Key and click on Save Changes.\nSuccess notification\nScroll down and click on Edit under Server Access Logging. Enable Server access logging by selecting Enable, entering s3:// kenya-one-bucket or you can click on “Browse S3” to add the Target bucket, and click on Save changes.\nSuccess notification. We have configured the ‘kenya-one-bucket’ to encrypt data. The user can now add data\nAlso, the ARN chosen in the Default Encryption section is “kenya-one-key”.\nKMS to Amazon EBS #\rAmazon EBS supports KMS. Its encryption provides data-at-rest security by encrypting data volumes, boot volumes, and snapshots using Amazon-managed keys or keys created and managed using AWS KMS.\nTo encrypt EBS volumes with the KMS master key, click on Services from the menu bar and search for EC2. From the search results, click on EC2 virtual servers in the cloud.\nOnce the EC2 Dashboard page opens, click on Volumes in the left pane under ELASTIC BLOCK STORE and click on Create Volume.\nIn the KMS Key field, select the kenya-one-key that was created: and click Create Volume\nMini Task\nNow, encrypt Amazon Redshift using the same KMS master key as you encrypted the EBS volume. By following the above steps, you can now as a cloud security engineer implement AWS KMS. Search for redshift in the services.\nCreate a workgroup (here, I named it ‘kenya-one-wg’)\nClick next and create a namespace(here , I named it ‘kenya-one-ns’)\nUnder the namespace creation page, head over to encryption and select add encryption and security. Paste in the ARN for our kenya-one-key created earlier .\nClick next, Review, and create.\nConclusion #\rImplementing AWS Key Management Service (KMS) enhances data security in the cloud by providing comprehensive key management capabilities, including creation, rotation, and access control, integrated seamlessly with other AWS services. It simplifies compliance with regulatory requirements through detailed logging and auditing, supports both symmetric and asymmetric keys for diverse use cases, and scales accordingly to meet growing organisational needs. By adopting AWS KMS, organizations can effectively protect sensitive data, streamline key management processes, reduce operational overhead, and ensure adherence to industry standards and best practices.\n","date":"20 August 2024","externalUrl":null,"permalink":"/posts/aws-key/","section":"Posts","summary":"Cloud security strategy article series","title":"AWS Key Management Implementation","type":"posts"},{"content":"","date":"20 August 2024","externalUrl":null,"permalink":"/tags/cloud/","section":"Tags","summary":"","title":"Cloud","type":"tags"},{"content":"","date":"20 August 2024","externalUrl":null,"permalink":"/categories/cloud/","section":"Categories","summary":"","title":"Cloud","type":"categories"},{"content":"","date":"20 August 2024","externalUrl":null,"permalink":"/categories/encryption/","section":"Categories","summary":"","title":"Encryption","type":"categories"},{"content":"","date":"20 August 2024","externalUrl":null,"permalink":"/tags/keys/","section":"Tags","summary":"","title":"Keys","type":"tags"},{"content":"","date":"20 August 2024","externalUrl":null,"permalink":"/tags/security/","section":"Tags","summary":"","title":"Security","type":"tags"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"}]